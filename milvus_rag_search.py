#!/usr/bin/env python3
"""
Milvus Multimodal RAG ê²€ìƒ‰ ìœ í‹¸ë¦¬í‹°

ì‚¬ìš©ë²•:
    # í…ìŠ¤íŠ¸ ê²€ìƒ‰
    python milvus_rag_search.py --collection fire_news --query "í™”ì¬ ì‚¬ê±´" --mode text
    
    # ì´ë¯¸ì§€ ê²€ìƒ‰
    python milvus_rag_search.py --collection fire_news --image path/to/image.jpg --mode image
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
    python milvus_rag_search.py --collection fire_news --query "í™”ì¬" --image image.jpg --mode hybrid
"""

import argparse
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
import json

# Milvus imports
from pymilvus import connections, Collection, utility

# Embeddings
from langchain_community.embeddings import HuggingFaceEmbeddings

# CLIP for image embeddings
try:
    from transformers import CLIPProcessor, CLIPModel
    import torch
    from PIL import Image
    CLIP_AVAILABLE = True
except ImportError:
    CLIP_AVAILABLE = False

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class MilvusMultimodalRAG:
    def __init__(
        self,
        collection_name: str,
        milvus_host: str = "localhost",
        milvus_port: str = "19530"
    ):
        """
        Milvus Multimodal RAG ê²€ìƒ‰ í´ë˜ìŠ¤
        
        Args:
            collection_name: ê²€ìƒ‰í•  Milvus ì»¬ë ‰ì…˜ ì´ë¦„
            milvus_host: Milvus ì„œë²„ í˜¸ìŠ¤íŠ¸
            milvus_port: Milvus ì„œë²„ í¬íŠ¸
        """
        self.collection_name = collection_name
        
        # Milvus ì—°ê²°
        connections.connect(host=milvus_host, port=milvus_port)
        
        if not utility.has_collection(collection_name):
            raise ValueError(f"Collection '{collection_name}' does not exist")
        
        self.collection = Collection(collection_name)
        self.collection.load()
        
        logger.info(f"âœ… Connected to collection '{collection_name}' ({self.collection.num_entities} entities)")
        
        # í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸
        logger.info("Loading text embedding model...")
        self.text_embeddings = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            model_kwargs={'device': 'cuda' if self._check_cuda() else 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # ì´ë¯¸ì§€ ì„ë² ë”© ëª¨ë¸ (CLIP)
        self.clip_model = None
        self.clip_processor = None
        if CLIP_AVAILABLE:
            logger.info("Loading CLIP model for image embeddings...")
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(self.device)
            self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            logger.info(f"âœ… CLIP model loaded on {self.device}")

    def _check_cuda(self) -> bool:
        """CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False

    def search_by_text(
        self,
        query: str,
        top_k: int = 5,
        filter_expr: Optional[str] = None,
        output_fields: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            filter_expr: í•„í„° í‘œí˜„ì‹ (ì˜ˆ: 'category == "disaster"')
            output_fields: ë°˜í™˜í•  í•„ë“œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"Searching with text query: '{query}'")
        
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self.text_embeddings.embed_query(query)
        
        # ê¸°ë³¸ ì¶œë ¥ í•„ë“œ
        if output_fields is None:
            output_fields = ["doc_id", "title", "content", "date", "category", "topic", "url", "source"]
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        search_params = {
            "metric_type": "COSINE",
            "params": {"nprobe": 10}
        }
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.collection.search(
            data=[query_embedding],
            anns_field="text_embedding",
            param=search_params,
            limit=top_k,
            expr=filter_expr,
            output_fields=output_fields
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for hits in results:
            for hit in hits:
                result = {
                    "score": hit.score,
                    "id": hit.id,
                }
                result.update(hit.entity.fields)
                formatted_results.append(result)
        
        logger.info(f"Found {len(formatted_results)} results")
        return formatted_results

    def search_by_image(
        self,
        image_path: str,
        top_k: int = 5,
        filter_expr: Optional[str] = None,
        output_fields: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        ì´ë¯¸ì§€ë¡œ ê²€ìƒ‰
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            filter_expr: í•„í„° í‘œí˜„ì‹
            output_fields: ë°˜í™˜í•  í•„ë“œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not CLIP_AVAILABLE or self.clip_model is None:
            raise ValueError("CLIP model not available. Install transformers and torch.")
        
        logger.info(f"Searching with image: '{image_path}'")
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±
        image = Image.open(image_path).convert('RGB')
        inputs = self.clip_processor(images=image, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            image_features = self.clip_model.get_image_features(**inputs)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        
        query_embedding = image_features.cpu().numpy().flatten().tolist()
        
        # ê¸°ë³¸ ì¶œë ¥ í•„ë“œ
        if output_fields is None:
            output_fields = ["doc_id", "title", "content", "date", "category", "topic", "image_url", "image_caption"]
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        search_params = {
            "metric_type": "COSINE",
            "params": {"nprobe": 10}
        }
        
        # ê²€ìƒ‰ ì‹¤í–‰ (ì´ë¯¸ì§€ ì„ë² ë”© ì‚¬ìš©)
        results = self.collection.search(
            data=[query_embedding],
            anns_field="image_embedding",
            param=search_params,
            limit=top_k,
            expr=filter_expr,
            output_fields=output_fields
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for hits in results:
            for hit in hits:
                result = {
                    "score": hit.score,
                    "id": hit.id,
                }
                result.update(hit.entity.fields)
                formatted_results.append(result)
        
        logger.info(f"Found {len(formatted_results)} results")
        return formatted_results

    def hybrid_search(
        self,
        text_query: Optional[str] = None,
        image_path: Optional[str] = None,
        text_weight: float = 0.5,
        image_weight: float = 0.5,
        top_k: int = 5,
        filter_expr: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
        
        Args:
            text_query: í…ìŠ¤íŠ¸ ì¿¼ë¦¬
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            text_weight: í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            image_weight: ì´ë¯¸ì§€ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            filter_expr: í•„í„° í‘œí˜„ì‹
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("Performing hybrid search (text + image)")
        
        results_map = {}
        
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        if text_query:
            text_results = self.search_by_text(text_query, top_k=top_k*2, filter_expr=filter_expr)
            for result in text_results:
                doc_id = result['doc_id']
                if doc_id not in results_map:
                    results_map[doc_id] = {'data': result, 'score': 0}
                results_map[doc_id]['score'] += result['score'] * text_weight
        
        # ì´ë¯¸ì§€ ê²€ìƒ‰
        if image_path and CLIP_AVAILABLE:
            image_results = self.search_by_image(image_path, top_k=top_k*2, filter_expr=filter_expr)
            for result in image_results:
                doc_id = result['doc_id']
                if doc_id not in results_map:
                    results_map[doc_id] = {'data': result, 'score': 0}
                results_map[doc_id]['score'] += result['score'] * image_weight
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(
            results_map.values(),
            key=lambda x: x['score'],
            reverse=True
        )[:top_k]
        
        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for item in sorted_results:
            result = item['data']
            result['hybrid_score'] = item['score']
            formatted_results.append(result)
        
        logger.info(f"Found {len(formatted_results)} hybrid results")
        return formatted_results

    def search_with_metadata_filter(
        self,
        query: str,
        category: Optional[str] = None,
        topic: Optional[str] = None,
        date_start: Optional[str] = None,
        date_end: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ë©”íƒ€ë°ì´í„° í•„í„°ë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            category: ì¹´í…Œê³ ë¦¬ í•„í„°
            topic: í† í”½ í•„í„°
            date_start: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
            date_end: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # í•„í„° í‘œí˜„ì‹ êµ¬ì„±
        filter_parts = []
        
        if category:
            filter_parts.append(f'category == "{category}"')
        
        if topic:
            filter_parts.append(f'topic == "{topic}"')
        
        if date_start:
            filter_parts.append(f'date >= "{date_start}"')
        
        if date_end:
            filter_parts.append(f'date <= "{date_end}"')
        
        filter_expr = " && ".join(filter_parts) if filter_parts else None
        
        logger.info(f"Searching with filter: {filter_expr}")
        
        return self.search_by_text(query, top_k=top_k, filter_expr=filter_expr)

    def print_results(self, results: List[Dict[str, Any]], show_content: bool = False):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
        print("\n" + "="*80)
        print(f"ğŸ” Search Results ({len(results)} items)")
        print("="*80)
        
        for idx, result in enumerate(results, 1):
            print(f"\nğŸ“„ Result #{idx}")
            print(f"   Score: {result.get('score', result.get('hybrid_score', 0)):.4f}")
            print(f"   Title: {result.get('title', 'N/A')}")
            print(f"   Date: {result.get('date', 'N/A')}")
            print(f"   Category: {result.get('category', 'N/A')} | Topic: {result.get('topic', 'N/A')}")
            print(f"   Source: {result.get('source', 'N/A')}")
            
            if result.get('url'):
                print(f"   URL: {result['url']}")
            
            if result.get('has_image'):
                print(f"   ğŸ–¼ï¸ Image: {result.get('image_url', 'N/A')}")
            
            if show_content and result.get('content'):
                content = result['content'][:200] + "..." if len(result['content']) > 200 else result['content']
                print(f"   Content: {content}")
            
            print("-" * 80)


def main():
    parser = argparse.ArgumentParser(description='Milvus Multimodal RAG Search')
    parser.add_argument('--collection', '-c', required=True,
                       help='Milvus collection name')
    parser.add_argument('--query', '-q',
                       help='Text query')
    parser.add_argument('--image', '-img',
                       help='Image file path')
    parser.add_argument('--mode', '-m', choices=['text', 'image', 'hybrid'], default='text',
                       help='Search mode: text, image, or hybrid')
    parser.add_argument('--top-k', '-k', type=int, default=5,
                       help='Number of results to return')
    parser.add_argument('--category',
                       help='Filter by category')
    parser.add_argument('--topic',
                       help='Filter by topic')
    parser.add_argument('--date-start',
                       help='Filter by start date (YYYYMMDD)')
    parser.add_argument('--date-end',
                       help='Filter by end date (YYYYMMDD)')
    parser.add_argument('--show-content', action='store_true',
                       help='Show content in results')
    parser.add_argument('--milvus-host', default='localhost',
                       help='Milvus server host')
    parser.add_argument('--milvus-port', default='19530',
                       help='Milvus server port')
    parser.add_argument('--output', '-o',
                       help='Output JSON file for results')
    
    args = parser.parse_args()
    
    # RAG ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
    try:
        rag = MilvusMultimodalRAG(
            collection_name=args.collection,
            milvus_host=args.milvus_host,
            milvus_port=args.milvus_port
        )
    except Exception as e:
        logger.error(f"Failed to initialize RAG: {e}")
        return
    
    # ê²€ìƒ‰ ì‹¤í–‰
    results = []
    
    try:
        if args.mode == 'text':
            if not args.query:
                logger.error("Text query required for text mode")
                return
            
            # ë©”íƒ€ë°ì´í„° í•„í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if args.category or args.topic or args.date_start or args.date_end:
                results = rag.search_with_metadata_filter(
                    query=args.query,
                    category=args.category,
                    topic=args.topic,
                    date_start=args.date_start,
                    date_end=args.date_end,
                    top_k=args.top_k
                )
            else:
                results = rag.search_by_text(args.query, top_k=args.top_k)
        
        elif args.mode == 'image':
            if not args.image:
                logger.error("Image path required for image mode")
                return
            results = rag.search_by_image(args.image, top_k=args.top_k)
        
        elif args.mode == 'hybrid':
            if not args.query and not args.image:
                logger.error("At least one of query or image required for hybrid mode")
                return
            results = rag.hybrid_search(
                text_query=args.query,
                image_path=args.image,
                top_k=args.top_k
            )
        
        # ê²°ê³¼ ì¶œë ¥
        rag.print_results(results, show_content=args.show_content)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì )
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"Results saved to {args.output}")
    
    except Exception as e:
        logger.error(f"Search failed: {e}")


if __name__ == "__main__":
    main()

